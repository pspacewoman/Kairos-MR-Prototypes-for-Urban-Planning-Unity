# ⛩️ KAIROS MR-Prototypes for Urban Planning in Unity  
### 🎓 Augmented Reality Application for Collaborative Learning  

[![Unity](https://img.shields.io/badge/Engine-Unity-000?logo=unity&logoColor=white)](https://unity.com/)  
[![C#](https://img.shields.io/badge/Code-C%23-239120?logo=c-sharp&logoColor=white)](https://learn.microsoft.com/en-us/dotnet/csharp/)  
[![XR Toolkit](https://img.shields.io/badge/Framework-XR%20Interaction%20Toolkit-blue?logo=unity&logoColor=white)](https://docs.unity3d.com/Packages/com.unity.xr.interaction.toolkit@2.0/manual/index.html)  
[![AR/VR](https://img.shields.io/badge/Focus-AR%20%7C%20VR-ff69b4?logo=oculus&logoColor=white)](https://www.oculus.com/)  
[![Research](https://img.shields.io/badge/Domain-HCI%20%7C%20UX-orange)](https://en.wikipedia.org/wiki/Human–computer_interaction)  
[![SPSS](https://img.shields.io/badge/Analysis-SPSS-lightgrey?logo=ibm&logoColor=blue)](https://www.ibm.com/spss)  
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)  

🔗 [Projekt-KAIROS Website](https://www.projekt-kairos.de)  


---

## 📖 About KAIROS Project

The **KAIROS Project** is a research initiative led by **FernUniversität in Hagen** in collaboration with municipal and industry partners.  
It explores how **Mixed Reality (MR)** and **cyber-physical systems** can enhance **citizen participation in urban planning**.  

## 🔍 Initial Situation vs. 🎯 Goal

| **Initial Situation** | **KAIROS Goal** |
|------------------------|-----------------|
| Citizen participation often limited to **analog meetings** (info events, public evenings). | Combine **analog + digital participation** using MR technologies. |
| Planning **not on-site**; discussions abstract. | Enable **on-site, immersive visualization** via AR/MR. |
| Drafts are **hard to visualize, comment, or modify**. | Create **interactive 3D models** citizens can view, comment, and change in real time. |
| Citizens struggle to engage fully with static plans. | Support **human-centered, engaging participation** that improves collaboration. |
| 📄 Analog Meetings → 🗣️ Discussion → ❌ Limited Visualization → ⚡ Low Engagement | 📄 Analog Input → 💻 Automatic Digital 3D Model → 🥽 Mixed Reality On-Site → ✅ Interactive, Human-Centered Participation   |

## 📖 **Prototype Solution**
💡 The prototype explores how immersive technology can **enhance engagement, teamwork, and comprehension** in higher education and public forums.  
💡 **Prototype an AR app** that makes collaborative learning and urban design **engaging, intuitive, and interactive**.  

## 👩‍💻 Project Details

| **Category** | **Details** |
|--------------|-------------|
| **My Role**  | Unity AR Developer · Scientific Research Assistant |
| **Team**     | PhD Researchers · Designers · UI Artists |
| **Partners** | NetZFactor GmbH · City of Bad Berleburg · Municipality of Erndtebrück |
| **Duration** | 2024 – Present |
| **Tools**    | Unity · C# · XR Interaction Toolkit · Meta Quest SDK · GitHub · Agile |

---

## 🔍 Research & Insights  
✅ **Workshops Conducted:**  
- Held in multiple cities with researchers and citizens.  
- Tested AR app on **Meta Quest headsets**.  
- Findings: High engagement, improved comprehension with 3D interaction.  

---

## 🎨 Design Process (HCI / UCD Framework)  
🌀 Steps:  
1. Research (literature + user needs)  
2. Concept Development  
3. Prototyping in Unity  
4. Usability Testing (workshops)  
5. Refinement & Iteration  

---

## 🛠 Prototyping in Unity  
**Implementation Highlights:**  
- 📦 Interactive 3D AR overlay scenes  
- 🕹 Gesture + controller input (XR Interaction Toolkit)  
- 🔍 Marker detection via custom C# scripts  
- 📝 UI menus for Whiteboard · Draw · Input Equation  
- 🚀 Deployment on Meta Quest, WebGL & Desktop  

---

## 🎮 Prototype Development Flow  

💡 Idea → 🎨 Design (Figma/UI Mockups) → 🖥️ Unity Setup → 🛠️ C# + XR Toolkit → 🥽 Meta Quest Build → ✅ Functional AR Prototype  

| 💡 Idea | 🎨 Design (Figma / UI Mockups) | 🖥️ Unity Setup | 🛠️ C# + XR Toolkit | 🥽 Meta Quest Build | ✅ Functional AR Prototype |
|---------|-------------------------------|----------------|-------------------|---------------------|----------------------------|

---

## 🎮 User Interaction Flow (Meta Quest 3)  

👤 User puts on headset → 🚀 Launches AR App → 🏙️ City objects overlayed in scene → 🎮 User selects/controls objects via controller → 📦 Places, rotates, resizes objects in free locations →  🔍 Tests and interacts with redesigned city environment →  ✅ Usability testing conducted  

---

## 📝 Feedback Collection & Analysis  

🗣️ Think-Aloud Feedback → 🎥 Screen Recording (Meta Quest Developer Hub) → 🎤 Audio Recording (Phone Devices) → 📑 Questionnaire + Interviews → 📊 Survey Feedback Documented → 🖋️ MAXQDA Transcript Coding & Analysis → 🎬 Prototype Videos Reviewed → ✅ Final Usability Insights & Recommendations  

---


